# GuÃ­a de IntegraciÃ³n Android - Tomato Disease Detection

## ğŸ“± Requisitos del Sistema
- Android API 21+ (Android 5.0 Lollipop)
- CÃ¡mara del dispositivo
- MÃ­nimo 2GB RAM
- 50MB de almacenamiento libre

**Nota importante (JDK/Gradle):** El Android Gradle Plugin moderno requiere Java 17. AsegÃºrate de que Android Studio/Gradle use JDK 17.
- En Android Studio: File â†’ Settings â†’ Build, Execution, Deployment â†’ Build Tools â†’ Gradle â†’ Gradle JDK â†’ seleccionar JDK 17.
- Alternativamente, configura `org.gradle.java.home=/ruta/a/jdk17` en `~/.gradle/gradle.properties` o en el `gradle.properties` del proyecto.

## ğŸ“¦ Archivos Necesarios
- `tomato_disease_mobilenetv4.tflite` - Modelo TensorFlow Lite
- `model_info.json` - Metadatos del modelo

## ğŸ”§ Dependencias de Android Studio

### build.gradle (Module: app)
```gradle
dependencies {
    implementation 'org.tensorflow:tensorflow-lite:2.16.1'
    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:2.16.1'  // Para TF Select (solo si es necesario)
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.16.1'
    implementation 'org.tensorflow:tensorflow-lite-support:0.4.4'
    implementation 'androidx.camera:camera-camera2:1.3.0'
    implementation 'androidx.camera:camera-lifecycle:1.3.0'
    implementation 'androidx.camera:camera-view:1.3.0'
}
```

### AndroidManifest.xml
```xml
<uses-permission android:name="android.permission.CAMERA" />
<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />
<uses-feature android:name="android.hardware.camera" android:required="true" />
```

## ğŸš€ ImplementaciÃ³n BÃ¡sica

(Se incluye ejemplo de carga / preprocesado / inferencia en la guÃ­a completa del repo)

## ğŸ“± Optimizaciones para ProducciÃ³n

- GPU: usar `GpuDelegate()` en `Interpreter.Options()` si se desea acelerar en dispositivos compatibles.
- NNAPI: `options.setUseNNAPI(true)` puede ayudar en dispositivos que soporten NNAPI.

## ğŸ” Testing y ValidaciÃ³n
1. Probar con imÃ¡genes de cada clase de enfermedad
2. Verificar rendimiento en diferentes dispositivos
3. Medir latencia de inferencia
4. Validar precisiÃ³n vs modelo original

## ğŸ“Š MÃ©tricas Esperadas
- PrecisiÃ³n: ~95% (ajustar segÃºn `mobile_deployment/model_info.json`)
- Latencia: <200ms en dispositivos modernos
- TamaÃ±o del modelo: ~2-4MB (dependiendo de cuantizaciÃ³n)
- RAM usage: <100MB durante inferencia
